{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "667f5604-b2f2-4c15-aebe-018d0162cdcb",
   "metadata": {},
   "source": [
    "# **Regression Metrices**  \n",
    "[source](https://youtu.be/Ti7c-Hz7GSM?si=3WkbEQ8C8C3D8AtG)\n",
    "* MAE\n",
    "* MSE\n",
    "* RMSE\n",
    "* R2 Score\n",
    "* Adjusted R2 Score\n",
    "\n",
    "\n",
    "\n",
    "# Mean Absolute Error  (MAE)\n",
    "From its name it can be guesed that there are two main things involved in it.  \n",
    "1. Mean\n",
    "2. Absolute(Mode: ||)\n",
    "<br><br>\n",
    "![ytss](assets/MAE.png)\n",
    "<br><br>\n",
    "Sum of mode of differences of each individual y and predicted y is called absolute error,and to make it mean absolute error we devide this term by n.\n",
    "<br>\n",
    "<br>\n",
    "#### Advantages:\n",
    "1. **Gives the error in the same unit as output**. For example if the output column was package... and for any test data it predicted 1.5, it means that its 1.5 lakhs per Anum off of what it should have predicted.\n",
    "2. **Robust to outliers** Not that much but compared to other techniques it is a little.\n",
    "<br>\n",
    "\n",
    "#### Disadvantages:\n",
    "using Mean Absolute error creates a V-shaped graph which makes it impossible to differentiate at 0. [read_this_for_Explaination](https://www.geeksforgeeks.org/maths/why-is-the-absolute-value-function-not-differentiable-at-x-0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0534a10-f9c5-4b4a-ab6b-e806a06fa91a",
   "metadata": {},
   "source": [
    "# Mean Squared Error (MSE)\n",
    "Instead of absolute we use Squares  \n",
    "<br>\n",
    "![ytss](assets/MSE.png)  \n",
    "<br>\n",
    "#### Advantage:  \n",
    "It can be used as loss function (Used it in Simple Linear Regression earlier) because it does't have that sharp turn in the grpah, it has smooth U-shaped one.  \n",
    "#### Disadvantages:\n",
    "1. Doesn't give the result in the same unit as output, (gives the square of output)\n",
    "2. Penalizes the outliers too much. Outlier is already a too large or too small value... it will increase it even further having a major impact on the differences that we calculate during the formula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00abb93-be65-44e6-8fc7-27a9a14ad878",
   "metadata": {},
   "source": [
    "# Root Mean Squared Error (RMSE)  \n",
    "Everything same as MSE. only return output in the same column as output.  \n",
    "![ytss](assets/RMSE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc5838-ec04-48e0-bf70-89da378eeffb",
   "metadata": {},
   "source": [
    "# R2 Score  \n",
    "R2 Score, it's independent of whats the unit of output.. for example if we are in the scenerio where output is LPA (lakhs per anum) and we get the error to be 1.5, we can say that its okay. Contradictly if we get error of tolerated steering of automatic car to be 1.5 degrees, we would say that its not okay we have to further reduce it... so it depends on context whether our error is good enough or not, whereas R2 Score method is independent of that context. if it says the error is 0.73 and its decided that its tolerable, then it will be tolerable in every scenerio.\n",
    "\n",
    "in Rr2 score we compare how much good is regression line than mean line  \n",
    "Its also called coeff. of determination\n",
    "also called goodness of fit.  <br><br>\n",
    "\n",
    "R2 = 1 - (SSr/SSm)  where SSr is Squares Sum of error in Regression line and SSm is Sum of Squared Error in the mean line. \n",
    "<br><br>\n",
    "![ytss](assets/R2_score.png)\n",
    "<br><br>\n",
    "\n",
    "#### How to interpret.:\n",
    "**if R2 == 0**   \n",
    "it means that your regression line is giving same error as your mean line, which means there is no use of doing regression which means x-axis data is not being used at all. regression line is equal to mean line... it shhould not happen  \n",
    "**if R2 == 1**  \n",
    "it means SSr/SSm is equal to 0. which means that SSr = 0, which means that your regression line passing through each data point. ideal case.  \n",
    "**if R2 < 0: -ve**  \n",
    "it means SSr>SSm, meaning regression line is generating more error than mean... wth. it means model drew regression line 4km away from all data points.\n",
    "<br>\n",
    "**Random: if R2 == 0.8**  \n",
    "It means that 80% of output column's variance is being explained by input columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cee106-fcc3-4dc5-9bab-c77bb2f3872f",
   "metadata": {},
   "source": [
    "# Adjusted R2 Score  \n",
    "#### Drawback of R2 Score  \n",
    "Adding more columns increases R2, for example if we were able to explain 80% of variance with just one column (cgpa) and after that we add another column (iq), now R2 can explain lets say 90% of variance... its good, but it sometimes it also increases the variance even when the added column is completely irrelevant (temprature)   \n",
    "#### Solution  \n",
    "<br><br>\n",
    "![ytss](assets/R2_adj.png)<br><br>\n",
    "There is k in denomiator which is the number of columns...\n",
    "* now if an irrelevant column (temprature) was added the numerator will either be very slighlt reduced or will stay constant, but the denomator is sure to drop much more... now if the denominator is small number, the term after division will be bigger and then after subtraction from 1 it will be again very smaller... thats what happens when an irrlevant column  is added... R2 adjusted increases\n",
    "* If relevant column is addd... R2 value will increase resulting in decrease of numerator's value due to 1-R2... and in denominator sure it will increase as earlier but the increase in numerator will be way more then denominator. resulting in small term and after subtraction, totally R2 adjusted increases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
