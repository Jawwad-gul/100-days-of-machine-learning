{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e313c2d-1f7b-4749-a44e-5db271d4a18a",
   "metadata": {},
   "source": [
    "# [Problem With Sigmoid Function Way and the Solution](https://youtu.be/6bXOo0sxY5c?list=PLKnIA16_Rmvbr7zKYQuBfsVkjoLcJgxHH)  \n",
    "What we were doing in the sigmoid function was hope machine learning... we were running a loop 1000 times. each time selecting a random number between 0 to n(number of rows) and then using that number as an index to get the data and update the coefficients... thats not the machine learning way to do things.  \n",
    "\n",
    "### Whats the machine learning way?  \n",
    "the machine learning way to get the coefficients is to get a loss function. find its minima, then choose those coefficients at the minima.  \n",
    "#### How can loss function help?  \n",
    "Consider that you have two models. both are classifying all the data points correctly leaving none miss-classified. Loss function can help us get the better one from these two. Getting the best.  \n",
    "\n",
    "---\n",
    "\n",
    "Now there is a way to compare two model's performances called Maximum Likelihood  \n",
    "\n",
    "### Maximum Likelihood  \n",
    "Notations: \n",
    "1. G = class1\n",
    "2. R = class2\n",
    "Every data point is either R or G. and every data point has the probability of being either R or G and every point is either in positive region or negative region of line. (one region is supposed to be for only one class either R or G).\n",
    "\n",
    "**Maximum Likelihood** is the product of all the probabilities of data points But each point's probability has to be taken same as its colour.: like if data point is R, the probability of it being R will be taken.  \n",
    "Now the model which has larger Maximum Likelihood (result of the product) is considered better.    \n",
    "\n",
    "![ytss](assets/maxlik.png)\n",
    "### There is a problem with this.  \n",
    "since the probabilities that are being multiplied are always between 0 to 1. so the product will only get smaller and smaller as the number of rows increase and to top that off we are just disscussing everything in 2d upto this point. if the dimensions increase. then who knows how small will the product get... it gets too small to the point where it can't be trusted as a measure to determine the performance.  \n",
    "### Solution:  \n",
    "We have to find to a way to change it into a sum...   \n",
    "take log of every probability. and add them together. now log of every number between 0 and 1 is always negative... so instead of adding them all up we change their signs and put negative with all of them. This loss function is called cross entropy.  \n",
    "now maximum likelihood was meant to be maximized... i mean maximum likelihood atmaximum meant better performance but its oppste int cross entropy. why? because \n",
    "-log(0.1) > -log(0.9) smaller number after getting in log is getting bigger. so the logic reverses.  \n",
    "<br>\n",
    "\n",
    "![ytss](assets/crossEntropy.png)   \n",
    "<br>\n",
    "\n",
    "## Finalization of loss function\n",
    "Earlier we just said that for every G point probabilty if it being G is taken and for every R point probability of it being R is taken. but how? \n",
    "This is how:  \n",
    "for every Yi, when its green the second term which is its probability of being red will become 0, since 1-1 is 0 making the whole term 0. and for every Yi, when its red, the first term will become 0. (ss:)\n",
    "\n",
    "![ytss](assets/loss.png)  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "###### Now unfortuantely there is no closed form solution for this loss function unlike in linear regression where we had one.  \n",
    "Its now an optimization technique like gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f17719e-1bd6-466b-960f-86835594eff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
