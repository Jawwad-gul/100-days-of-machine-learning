{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51db1307-2caf-4d0b-905f-c1e641ca141d",
   "metadata": {},
   "source": [
    "# Simple Linear Regression (Math Behind it and then manual algorithm building.)\n",
    "[source](https://youtu.be/dXHIDLPKdmA?list=PLKnIA16_Rmvbr7zKYQuBfsVkjoLcJgxHH)\n",
    "\n",
    "---\n",
    "\n",
    "![ytss](assets/SLR.png) \n",
    "<br><br>\n",
    "The problem we are focusing on is how to find m and b used in y = mx + b equation.  \n",
    "There are two ways to do that.\n",
    "1. **Closed Form Solution**<br>\n",
    "   Means using any mathematical formula. the technique used here is called _OLS(Ordinary Least Squares)_.`sklearn.linear_model.LinearRegression` also uses this technique\n",
    "2. **Non-Closed Form Solution**<br>\n",
    "   the technique used in here is called _Gradient Descent_. the difference is that OLS can't work in high dimensional data as well as it can in low           dimensions. so thats why Gradient Descent was made. class: `sklearn.linear_model.SGDRegressor`\n",
    "---\n",
    "#### Now we are focusing on OLS:\n",
    "The formulas used in OLS to calculate the values of m and b are in the following SS:<br>\n",
    "![ytss](assets/SLR_math.png)\n",
    "<br><br>\n",
    "But this is not an achievement to know whats the formula and then apply it... the real thing is to find out **why is this the formual?**<br><br>\n",
    "\n",
    "What is the first problem?  \n",
    "the problem with linear regression is that the line which the model finalizes can't pass through each data point. so it tends to find the **Best Fit** (line which is closest to all the points). but even the best fit has room for error. because even though its near to data points there is still some distance between the line and the data points. some are a little bit more further while others are a bit near. ultimately every data point does have that distance... _Sum of square of each distance is called Error Function/Loss Function_<br><br>\n",
    "![ytss](assets/SLR_Error_Function.png)<br><br>\n",
    "the data point's value whether its predicted by model or original itself, its x-axis value doesn't change. only thing that changes is the value of y and thats exactly how it should be because y is our target column. so now to calculate the distance d in the formula given in the ss. we have to calculate the difference between predicted data point and actual data point along the y-axis. which will be `yi - yi^` (yi= actual data point's value along y-axis, and yi^ is predicted value). `yi^ = mxi + b`<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "**Mission is to find the values of m and b where Error's value reduces to minimum. then using those m and b we can draw our regression best fit line.**\n",
    "To find the values of m and b we take the differential of Error function and make it equal to 0. because differential tells us abou the slope at any instant and when the differential is 0 it means that slope is at its lowest.\n",
    "<br>\n",
    "![ytss](assets/SLR_differential.png) \n",
    "<br><br>\n",
    "Have to take partial differential of both m and b separately because differential can only be taken of one variable (If E only depended on one variable say g we would have done dE/dg)<br><br>\n",
    "#### Below is how to find b:\n",
    "<table style='margin:0; padding:0;'>\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; width:50%;\">\n",
    "<strong> Assumptions: </strong>\n",
    "    <ul>\n",
    "    <li> b is only variable.\n",
    "    <li> m,x,y are always constants.\n",
    "    <li> The Error function is equal to 0 because thats where slope is minimum (further explained above)\n",
    "    <li> Goal is to find the intercept value (b)\n",
    "    </ul>\n",
    "Also one thing that I haven't explain in the picture is how the sums of b n times devided my n became just b\n",
    "its actually quite easy... take this example.. (x+x+x+x+x)/5 = 5x/5 = x\n",
    "</td>\n",
    "<td style=\"width:50%;\">\n",
    "<img src=\"assets/b_derived1.PNG\" width=\"450\" style='float:right;'>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "#### Using b, here is how m is found:\n",
    "<table style='margin:0; padding:0;'>\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; width:50%;\">\n",
    "<strong> Notes: </strong>\n",
    "    Everything is pretty much self explanatory... oh, I forgot to multiply one term at a place where I have drew arrows\n",
    "</td>\n",
    "<td style=\"width:50%;\">\n",
    "<img src=\"assets/m_derived.png\" width=\"450\" style='float:right;'>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d8b6fd-a7e2-4b64-9776-95ad10c6f5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac581b92-a9d2-4956-828c-ab778326d34d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
