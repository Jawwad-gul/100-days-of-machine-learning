{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf0b7e6-b266-4be1-9190-95b1cd485d75",
   "metadata": {},
   "source": [
    "# Stochastic Gradient descent  \n",
    "[source](https://www.youtube.com/watch?v=V7KBAa_gh4c&list=PLKnIA16_Rmvbr7zKYQuBfsVkjoLcJgxHH&index=58&pp=iAQB)\n",
    "### Draw back of Batch radient Descent:  \n",
    "1. **Number of Computations** <br>\n",
    "For calculation of every column's coefficient + intercept's, we have to calculate n number of derivates, and then this process is done epoch number of times.\n",
    "For example, you have rows = 1000, columns = 5 (meaning 5+1 coefficent), epochs = 100. you will have to calculate 1000 x 6 x 100 = 600000 calculations of derivates. thats huge.. and this examplory dataset wasn't that big.. its below average.\n",
    "2. **Hardware**<br>\n",
    "While doing vectorization, you have to load whole X_train into ram. if you are working with big data you will need as much bigger ram. so **resource intensive**\n",
    "\n",
    "In Batch, we update the coefficeints after going through all of the data (1epoch = 1 update),  \n",
    "In stochastic, we update the coefficients after each row, so you are doing updates more frequently, large number of updates make you reach the convergence quickly (converged: minimum values of coefficients) so you would also need less number of epochs    \n",
    "<br>\n",
    "In schotastic we dont need to load the whole dataset, instead only one row can be loaded  \n",
    "\n",
    "Now we know that it picks one row and updates the coefficients through that. that row is picked at random, because of random pick, this solution (stochastic gd) is not steady sollution, every time it gives different results.. but they are close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ca2341-1037-4dd9-8636-0dc3a1fcee79",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42b2d5b4-5730-4f2a-a479-7a14715c61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "995f202e-9874-4776-884f-2ead7907df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_diabetes()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd7e2548-6994-442e-803a-715dd228329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9688acc6-7711-432f-84e0-12e4c74b5316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4399338661568969"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83675433-e454-4e08-928f-2dd81b12a0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  -9.15865318 -205.45432163  516.69374454  340.61999905 -895.5520019\n",
      "  561.22067904  153.89310954  126.73139688  861.12700152   52.42112238]\n"
     ]
    }
   ],
   "source": [
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05c382f7-6c0c-41ed-83aa-0432180ec62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.88331005254167\n"
     ]
    }
   ],
   "source": [
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "0210448c-a323-400a-a319-468635e3c316",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD_Regressor:\n",
    "    def __init__(self,lr=0.01,epochs=100):\n",
    "    \n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "    def fit(self,X_train,y_train):\n",
    "        # intializing coefficients: \n",
    "        self.intercept_ = 0\n",
    "        self.coef_ = np.ones(X_train.shape[1])\n",
    "        # print(self.intercept_,self.coef_) \n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            idx = np.random.randint(0,X_train.shape[0])\n",
    "            y_hat = np.dot(X_train[idx],self.coef_) + self.intercept_ # taking one row instead of whole X_train\n",
    "\n",
    "            lr_t = self.lr / (1 + 0.0001 * i)# reducing learning rate with each epoch to reduce randomness near convergence.\n",
    "            \n",
    "            # updating intercept\n",
    "            inter_der = -2 * (y_train[idx] - y_hat)\n",
    "            self.intercept_ = self.intercept_ - (lr_t * inter_der)\n",
    "\n",
    "            # updating coef\n",
    "            coef_der = -2 * np.dot((y_train[idx]- y_hat) , X_train[idx])\n",
    "            self.coef_ = self.coef_ - (lr_t * coef_der)\n",
    "   \n",
    "        print(self.intercept_,self.coef_)\n",
    "        \n",
    "    def predict(self,X_test):\n",
    "        return np.dot(X_test,self.coef_) + self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "1e6fcb21-673f-470f-bd5b-5603df80e519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148.61898497145143 [  38.51097004 -162.10556453  471.90050959  297.30738209  -43.53146628\n",
      " -102.79441453 -204.26658905  100.23392508  406.07460236  120.21988358]\n",
      "time taken:  0.35077691078186035\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "sgd = SGD_Regressor(lr = 0.1, epochs = 5000)\n",
    "start = time.time()\n",
    "sgd.fit(X_train,y_train)\n",
    "print('time taken: ',time.time() - start) #  even though epochs are higher, the time takes is less than batch gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "013cb049-ba9c-418b-b7bf-f9dbb795fa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45490112697487217"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1 = sgd.predict(X_test)\n",
    "r2_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a64a99c-aef4-4722-9fbc-08cf0bb0140b",
   "metadata": {},
   "source": [
    "![ytss](assets/sgdVSbgd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ed639a-6973-4295-9f6a-b685e112e75d",
   "metadata": {},
   "source": [
    "on the right, in both grpahs s behaviour of Stochastic while on left is batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cb487a-83da-4201-8560-8c5d161030c8",
   "metadata": {},
   "source": [
    "## Using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "c7ae7a7b-3e80-4513-b7c3-16590a9b5a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  24.73926533 -149.24748997  459.29686781  307.07156088  -27.005906\n",
      "  -98.01854655 -191.0497421   109.3303328   417.73507253  107.62713172] [152.03552604]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jawwa\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1608: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4542511346032271"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd = SGDRegressor(\n",
    "    loss=\"squared_error\",\n",
    "    penalty=\"l2\",\n",
    "    max_iter=6800,\n",
    "    learning_rate=\"invscaling\",\n",
    "    eta0=0.01\n",
    ")\n",
    "\n",
    "sgd.fit(X_train, y_train)\n",
    "print(sgd.coef_, sgd.intercept_)\n",
    "r2_score(y_test,sgd.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "148f5d17-21c4-4f8d-a0bb-23d60b35808e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0001 * 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd56f41-6b57-434c-b22a-7229a0ecec36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
