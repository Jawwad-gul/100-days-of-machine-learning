{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a148ac07-e6c8-43c2-b8d4-1c25deea3c7f",
   "metadata": {},
   "source": [
    "# [Key Take Aways of RIDGE Regression](https://youtu.be/8osKeShYVRQ?list=PLKnIA16_Rmvbr7zKYQuBfsVkjoLcJgxHH)  \n",
    "### 1.  Affect of shrinkage coefficent(alpha) on coefficients\n",
    "    Larger and larger values of alpha will reduce the coefficients more and more but it will never be 0.\n",
    "### 2. Large coefficients will be more affected then smaller ones  \n",
    "    Suppose data with three feature, like: X1,X2,X3 and y... and suppose coefficeints like, m1 = 1000,m2=60,m3=27.. (meaning value of y depends the most on X1) applying ridge regression here the value of m1 will reduce more than the others\n",
    "### 3. Bias Variance Tradeoff\n",
    "![ytss](assets/bv.png)  \n",
    "we need both bias and variance to be minimum... thats why that alpha is a hyperparameter..  \n",
    "### 4. Impact on Loss Function  \n",
    "overall decreases. let's say you have intercept as constant... if you keep increasing the value of lamda in the loss function and plot the value of coefficient for each one.. you would notice that minima is slowly going toward m. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7392fca4-5342-471e-9f69-28daaa255120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
