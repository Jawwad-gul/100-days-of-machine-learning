{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87512aa9-7358-4f56-b343-6a7f1defbb61",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours (KNN)  \n",
    "[source](https://www.youtube.com/watch?v=-fK-xEev2I8&list=PLKnIA16_Rmvbr7zKYQuBfsVkjoLcJgxHH&index=39)  \n",
    "<br><br>\n",
    "![ytss](assets/KNN_intro.png)\n",
    "<br><br>\n",
    "\n",
    "The formula is almost similar to *Euclidean Distance's* formula, only difference is a new term called weight. its calculated by : `How much features are we taking into account / how much features have non-null values` in the observations chosen by \"K\", this the example shown in the picture its giong to be 3/3 so ultimately being 1, meaning this time it would be exactly same as euclidean distance's formula.\n",
    "In the above example I can understand what's going on.\n",
    "See the following examples in ss as well:  <br><br>\n",
    "![ytss](assets/KNN_example.png) <br><br>\n",
    "\n",
    "After finding out the nan-euclidean distance to k-number of closest observations. next thing is to take values from that same feature (where you are imputing) but from closest observations (How much observations? k) determined by nan-euclidean formuala and then take their mean and then simply impute the null value with it  \n",
    "<br>\n",
    "\n",
    "## Advantages & Disadvantages\n",
    "* More accurate\n",
    "* More Calculations\n",
    "* Whole Training set has to be uploaded to server in production environmen: (speed slowed, memory usage more)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c5e46c-b93d-47c3-b693-6f85dda623d3",
   "metadata": {},
   "source": [
    "## Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c2a78bd-733f-4d9f-8372-a88f5d7997e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b15059d5-c843-4546-92c2-5a0cfd1b5165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age     Fare\n",
       "0         0       3  22.0   7.2500\n",
       "1         1       1  38.0  71.2833\n",
       "2         1       3  26.0   7.9250\n",
       "3         1       1  35.0  53.1000\n",
       "4         0       3  35.0   8.0500"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('assets/Titanic-Dataset.csv',usecols=['Age','Fare','Pclass','Survived'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d967770e-1b63-4694-b231-b49a8d49650a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived     0.00000\n",
       "Pclass       0.00000\n",
       "Age         19.86532\n",
       "Fare         0.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f0b43a5-f294-4196-b8f0-5ecbffdfa3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Survived',axis=1)\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "02d5f04b-8016-4d95-ab48-0295fd2e37d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af29bb7a-bf46-41b6-aea4-628f3e20c193",
   "metadata": {},
   "source": [
    "# KNNImputer `weights` Params \n",
    "```python\n",
    "weights=['distance','uniform']#uniform is default\n",
    "```\n",
    "\n",
    "## Example:\n",
    "\n",
    "We want to fill in a missing value (say, **Age**) using **KNNImputer**.  \n",
    "We found our 3 closest neighbors and their distances:\n",
    "\n",
    "| Neighbor | Distance from missing row | Age (value to use) |\n",
    "|-----------|---------------------------|--------------------|\n",
    "| 1 | 1.0 | 10 |\n",
    "| 2 | 2.0 | 12 |\n",
    "| 3 | 4.0 | 9 |\n",
    "\n",
    "---\n",
    "\n",
    "###  1. Uniform weighting (`weights='uniform'`)\n",
    "\n",
    "All neighbors are treated equally — it doesn’t matter if they are close or far.  \n",
    "We just take the mean of their “Age” values:\n",
    "\n",
    "(10 + 12 + 9) / 3 = 31 / 3 = 10.33\n",
    "\n",
    "\n",
    "\n",
    " **Imputed Age = 10.33**\n",
    "\n",
    "---\n",
    "\n",
    "###  2. Distance weighting (`weights='distance'`)\n",
    "\n",
    "Here, closer neighbors get **more importance** (more “weight”) than farther ones.\n",
    "\n",
    "**Step 1: Inverse of distances**\n",
    "\n",
    "| Neighbor | Distance | 1 / Distance |\n",
    "|-----------|-----------|--------------|\n",
    "| 1 | 1.0 | 1.00 |\n",
    "| 2 | 2.0 | 0.50 |\n",
    "| 3 | 4.0 | 0.25 |\n",
    "\n",
    "**Step 2: Add them up**\n",
    "\n",
    "Total = 1.00 + 0.50 + 0.25 = 1.75\n",
    "\n",
    "\n",
    "**Step 3: Convert to proportions (weights)**\n",
    "\n",
    "| Neighbor | 1/Distance | Weight (fraction of total) |\n",
    "|-----------|-------------|----------------------------|\n",
    "| 1 | 1.00 | 1.00 / 1.75 = 0.571 |\n",
    "| 2 | 0.50 | 0.50 / 1.75 = 0.286 |\n",
    "| 3 | 0.25 | 0.25 / 1.75 = 0.143 |\n",
    "\n",
    "**Step 4: Multiply each value by its weight**\n",
    "\n",
    "| Neighbor | Age | Weight | Contribution |\n",
    "|-----------|------|---------|--------------|\n",
    "| 1 | 10 | 0.571 | 5.71 |\n",
    "| 2 | 12 | 0.286 | 3.43 |\n",
    "| 3 | 9 | 0.143 | 1.29 |\n",
    "\n",
    "**Step 5: Add contributions**    \n",
    "\n",
    "Total = 5.71 + 3.43 + 1.29 = 10.43\n",
    "\n",
    "**Imputed Age = 10.43**\n",
    "\n",
    "---\n",
    "\n",
    "### Compare results\n",
    "\n",
    "| Method | Result | Explanation |\n",
    "|---------|---------|-------------|\n",
    "| **Uniform** | 10.33 | Simple average — all neighbors counted equally |\n",
    "| **Distance** | 10.43 | Closer neighbors have slightly more influence |\n",
    "\n",
    "---\n",
    "\n",
    "### Key takeaway\n",
    "\n",
    "- **Uniform weighting** → equal importance → simple average  \n",
    "- **Distance weighting** → close neighbors have **more say** → weighted average  \n",
    "- The difference is small here, but when distances vary a lot, distance-based gives a more realistic imputation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8cff9736-164d-4282-baf1-22f6c5d2c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNNImputer(n_neighbors=2,weights='uniform')# with weight='uniform' also giving same accuracy\n",
    "X_train_trf = knn.fit_transform(X_train)\n",
    "X_test_trf = knn.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ea3b6a0-a959-40e0-9308-9659866686d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass    0.0\n",
       "Age       0.0\n",
       "Fare      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_trf,columns=X_train.columns).isnull().mean()*100 #nulls gone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2913a34a-e28f-41d6-a228-6e6e1ed385a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7094972067039106"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_trf,y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test_trf)\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "105fd584-c4be-4fd4-859b-67d3ed7475e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# camparing with mean imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "42980fbd-42c0-4959-a4e7-714b97c52f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "si = SimpleImputer()\n",
    "\n",
    "X_train_trf2 = si.fit_transform(X_train)\n",
    "X_test_trf2 = si.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "73f600a6-26a7-4279-b4f8-24b3cc52fa2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6927374301675978"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_trf2,y_train)\n",
    "\n",
    "y_pred2 = lr.predict(X_test_trf2)\n",
    "\n",
    "accuracy_score(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdeddf7-70e4-4923-88fc-c6c14e05ff90",
   "metadata": {},
   "source": [
    "Difference is clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690fa6e7-6339-47e9-bd15-573d146e2ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
